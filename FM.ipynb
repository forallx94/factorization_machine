{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# FM\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.datasets import load_breast_cancer\r\n",
    "\r\n",
    "# GPU 확인\r\n",
    "tf.config.list_physical_devices('GPU')\r\n",
    "\r\n",
    "# 자료형 선언\r\n",
    "tf.keras.backend.set_floatx('float32')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\r\n",
    "#### 마스터 데이터(상호 작용)\r\n",
    "#### 상호 작용(transaction) 마스터 데이터를 불러옴\r\n",
    "masterdf = pd.read_csv('./data/Transactions.csv')\r\n",
    "masterdf.head()\r\n",
    "\r\n",
    "### 데이터 정리 및 표준화를 위해 데이터 열 명칭 변경\r\n",
    "### 표준화는 병합의 용의성을 위해 열 명칭을 정렬\r\n",
    "masterdf.columns = ['Transaction ID', 'Customer ID', 'Transaction Date', 'Prod Subcat Code',\r\n",
    "       'Prod Cat Code', 'Qty', 'Rate', 'Tax', 'Total Amt', 'Store Type']\r\n",
    "\r\n",
    "###  상점 코드 타입을 숫자형으로 변경하여 새 열에 저장\r\n",
    "masterdf['Store Type Code'] = pd.factorize(masterdf['Store Type'])[0]\r\n",
    "masterdf.head(5)\r\n",
    "\r\n",
    "### quantity와 based price에서 총 순 매출액(Net sales) 계산 (도시마다의 세금이 다를 수 있어 세금 제외)\r\n",
    "masterdf['Net Sales'] = masterdf['Qty'] * masterdf['Rate']\r\n",
    "\r\n",
    "### category, subcategory, store type을 이용하여 고유한 material 표시기를 생성\r\n",
    "### 다른 sku는 다른 상점 유형에 판매된다고 가정\r\n",
    "masterdf['Material'] = masterdf['Prod Cat Code'].astype(str) + '-' + masterdf['Prod Subcat Code'].astype(str) + '-' + masterdf['Store Type'].astype(str)\r\n",
    "\r\n",
    "masterdf[['Customer ID','Material','Net Sales']]\r\n",
    "\r\n",
    "scaler = MinMaxScaler()\r\n",
    "grade = scaler.fit_transform(masterdf[['Net Sales']])\r\n",
    "\r\n",
    "grade = pd.DataFrame(grade,columns=['grade'])\r\n",
    "cust = pd.get_dummies(masterdf['Customer ID'],prefix='cust')\r\n",
    "item = pd.get_dummies(masterdf['Material'],prefix='item')\r\n",
    "\r\n",
    "df = pd.concat([cust,item,grade], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# 데이터 로드\r\n",
    "X, Y = df[[i for i in df.columns if i!='grade']].to_numpy(), df[['grade']].to_numpy()\r\n",
    "X = X[:23050,:]\r\n",
    "Y = Y[:23050,:]\r\n",
    "\r\n",
    "n = X.shape[0]\r\n",
    "p = X.shape[1]\r\n",
    "\r\n",
    "k = 10\r\n",
    "batch_size = 8\r\n",
    "epochs = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "Y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.51009421],\n",
       "       [0.99798116],\n",
       "       [0.20349933],\n",
       "       ...,\n",
       "       [0.11009421],\n",
       "       [0.16069987],\n",
       "       [0.08169583]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "class FM(tf.keras.Model):\r\n",
    "    def __init__(self):\r\n",
    "        super(FM, self).__init__()\r\n",
    "\r\n",
    "        # 모델의 파라미터 정의\r\n",
    "        self.w_0 = tf.Variable([0.0])\r\n",
    "        self.w = tf.Variable(tf.zeros([p]))\r\n",
    "        self.V = tf.Variable(tf.random.normal(shape=(p, k)))\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        linear_terms = tf.reduce_sum(tf.math.multiply(self.w, inputs), axis=1)\r\n",
    "\r\n",
    "        interactions = 0.5 * tf.reduce_sum(\r\n",
    "            tf.math.pow(tf.matmul(inputs, self.V), 2)\r\n",
    "            - tf.matmul(tf.math.pow(inputs, 2), tf.math.pow(self.V, 2)),\r\n",
    "            1,\r\n",
    "            keepdims=False\r\n",
    "        )\r\n",
    "\r\n",
    "        y_hat = tf.math.sigmoid(self.w_0 + linear_terms + interactions)\r\n",
    "\r\n",
    "        return y_hat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Forward\r\n",
    "def train_on_batch(model, optimizer, accuracy, inputs, targets):\r\n",
    "    with tf.GradientTape() as tape:\r\n",
    "        y_pred = model(inputs)\r\n",
    "        loss = tf.keras.losses.mean_absolute_error(y_true=targets, y_pred=y_pred)\r\n",
    "    \r\n",
    "    # loss를 모델의 파라미터로 편미분하여 gradients를 구한다.\r\n",
    "    grads = tape.gradient(target=loss, sources=model.trainable_variables)\r\n",
    "\r\n",
    "    # apply_gradients()를 통해 processed gradients를 적용한다.\r\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n",
    "\r\n",
    "    # accuracy: update할 때마다 정확도는 누적되어 계산된다.\r\n",
    "    accuracy.update_state(targets, y_pred)\r\n",
    "\r\n",
    "    return loss\r\n",
    "\r\n",
    "\r\n",
    "# 반복 학습 함수\r\n",
    "# def train(epochs):\r\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\r\n",
    "\r\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\r\n",
    "    (tf.cast(X_train, tf.float32), tf.cast(Y_train, tf.float32))).shuffle(500).batch(8)\r\n",
    "\r\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\r\n",
    "    (tf.cast(X_test, tf.float32), tf.cast(Y_test, tf.float32))).shuffle(200).batch(8)\r\n",
    "\r\n",
    "model = FM()\r\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\r\n",
    "accuracy = MeanAbsoluteError()\r\n",
    "loss_history = []\r\n",
    "\r\n",
    "for i in range(50):\r\n",
    "    for x, y in train_ds:\r\n",
    "        loss = train_on_batch(model, optimizer, accuracy, x, y)\r\n",
    "        loss_history.append(loss)\r\n",
    "\r\n",
    "    if i % 2== 0:\r\n",
    "        print(\"스텝 {:03d}에서 누적 평균 손실: {:.4f}\".format(i, np.mean(loss_history)))\r\n",
    "        print(\"스텝 {:03d}에서 누적 정확도: {:.4f}\".format(i, accuracy.result().numpy()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "스텝 000에서 누적 평균 손실: 0.3201\n",
      "스텝 000에서 누적 정확도: 0.1651\n",
      "스텝 002에서 누적 평균 손실: 0.3033\n",
      "스텝 002에서 누적 정확도: 0.1504\n",
      "스텝 004에서 누적 평균 손실: 0.2986\n",
      "스텝 004에서 누적 정확도: 0.1463\n",
      "스텝 006에서 누적 평균 손실: 0.2959\n",
      "스텝 006에서 누적 정확도: 0.1439\n",
      "스텝 008에서 누적 평균 손실: 0.2937\n",
      "스텝 008에서 누적 정확도: 0.1421\n",
      "스텝 010에서 누적 평균 손실: 0.2919\n",
      "스텝 010에서 누적 정확도: 0.1405\n",
      "스텝 012에서 누적 평균 손실: 0.2902\n",
      "스텝 012에서 누적 정확도: 0.1390\n",
      "스텝 014에서 누적 평균 손실: 0.2885\n",
      "스텝 014에서 누적 정확도: 0.1376\n",
      "스텝 016에서 누적 평균 손실: 0.2869\n",
      "스텝 016에서 누적 정확도: 0.1363\n",
      "스텝 018에서 누적 평균 손실: 0.2853\n",
      "스텝 018에서 누적 정확도: 0.1349\n",
      "스텝 020에서 누적 평균 손실: 0.2836\n",
      "스텝 020에서 누적 정확도: 0.1335\n",
      "스텝 022에서 누적 평균 손실: 0.2818\n",
      "스텝 022에서 누적 정확도: 0.1321\n",
      "스텝 024에서 누적 평균 손실: 0.2800\n",
      "스텝 024에서 누적 정확도: 0.1306\n",
      "스텝 026에서 누적 평균 손실: 0.2782\n",
      "스텝 026에서 누적 정확도: 0.1291\n",
      "스텝 028에서 누적 평균 손실: 0.2762\n",
      "스텝 028에서 누적 정확도: 0.1276\n",
      "스텝 030에서 누적 평균 손실: 0.2743\n",
      "스텝 030에서 누적 정확도: 0.1260\n",
      "스텝 032에서 누적 평균 손실: 0.2722\n",
      "스텝 032에서 누적 정확도: 0.1243\n",
      "스텝 034에서 누적 평균 손실: 0.2702\n",
      "스텝 034에서 누적 정확도: 0.1227\n",
      "스텝 036에서 누적 평균 손실: 0.2680\n",
      "스텝 036에서 누적 정확도: 0.1210\n",
      "스텝 038에서 누적 평균 손실: 0.2659\n",
      "스텝 038에서 누적 정확도: 0.1193\n",
      "스텝 040에서 누적 평균 손실: 0.2637\n",
      "스텝 040에서 누적 정확도: 0.1175\n",
      "스텝 042에서 누적 평균 손실: 0.2616\n",
      "스텝 042에서 누적 정확도: 0.1159\n",
      "스텝 044에서 누적 평균 손실: 0.2596\n",
      "스텝 044에서 누적 정확도: 0.1142\n",
      "스텝 046에서 누적 평균 손실: 0.2576\n",
      "스텝 046에서 누적 정확도: 0.1126\n",
      "스텝 048에서 누적 평균 손실: 0.2557\n",
      "스텝 048에서 누적 정확도: 0.1111\n",
      "테스트 정확도: 0.0779\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "test_accuracy = MeanAbsoluteError()\r\n",
    "for x, y in test_ds:\r\n",
    "    y_pred = model(x)\r\n",
    "    test_accuracy.update_state(y, y_pred)\r\n",
    "\r\n",
    "print(\"테스트 정확도: {:.4f}\".format(test_accuracy.result().numpy()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "테스트 정확도: 0.2154\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('py38tf2': conda)"
  },
  "interpreter": {
   "hash": "f786b47412788e78e454191c2f87ff8c55e16bdd567362c780933370cac632e2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}